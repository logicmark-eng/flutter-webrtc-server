name: Deploy Flutter WebRTC Server

on:
  push:
    branches:
      - master
    tags:
      - 'v*.*.*'
  workflow_dispatch:
    inputs:
      version:
        description: 'Version tag (e.g., v0.0.7) - leave empty for auto-generation'
        required: false
        type: string

env:
  S3_BUCKET: ota-img-dev.lgmk-eng.com
  AWS_REGION: us-east-1
  SERVICE_NAME: flutter-webrtc.service
  INFRA_PROJECT_PATH: ../lgmk-pers-base-infra

jobs:
  build:
    name: Build and Package
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.version.outputs.version }}
      zip_filename: ${{ steps.version.outputs.zip_filename }}
      environment: ${{ steps.environment.outputs.environment }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Determine environment
        id: environment
        run: |
          # Currently only master branch exists, deploying to develop environment
          ENVIRONMENT="develop"

          echo "environment=${ENVIRONMENT}" >> $GITHUB_OUTPUT
          echo "ðŸŽ¯ Target environment: ${ENVIRONMENT}"

      - name: Determine version
        id: version
        run: |
          if [[ "${{ github.ref }}" == refs/tags/* ]]; then
            VERSION="${GITHUB_REF#refs/tags/}"
          elif [[ "${{ github.event_name }}" == "workflow_dispatch" && -n "${{ github.event.inputs.version }}" ]]; then
            VERSION="${{ github.event.inputs.version }}"
          else
            # Generate version from branch and commit
            BRANCH_NAME="${GITHUB_REF#refs/heads/}"
            VERSION="v0.0.0-${BRANCH_NAME}-${GITHUB_SHA::7}"
          fi

          ZIP_FILENAME="flutter-webrtc-server-master${VERSION}.zip"

          echo "version=${VERSION}" >> $GITHUB_OUTPUT
          echo "zip_filename=${ZIP_FILENAME}" >> $GITHUB_OUTPUT
          echo "ðŸ“¦ Version: ${VERSION}"
          echo "ðŸ“¦ ZIP filename: ${ZIP_FILENAME}"

      - name: Create deployment package
        run: |
          echo "ðŸ“¦ Creating deployment package..."

          # Create a clean archive excluding unnecessary files
          zip -r "${{ steps.version.outputs.zip_filename }}" . \
            -x "*.git*" \
            -x "*.github*" \
            -x "*bin/*" \
            -x "*.zip" \
            -x "*node_modules/*" \
            -x "*.DS_Store" \
            -x "*__pycache__/*" \
            -x "*.vscode/*" \
            -x "*.idea/*"

          echo "âœ… Package created"
          ls -lh "${{ steps.version.outputs.zip_filename }}"

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: webrtc-server-package
          path: ${{ steps.version.outputs.zip_filename }}
          retention-days: 30

  deploy:
    name: Deploy to ${{ needs.build.outputs.environment }}
    needs: build
    runs-on: ubuntu-latest
    environment: ${{ needs.build.outputs.environment }}
    permissions:
      id-token: write
      contents: read

    steps:
      - name: Download artifact
        uses: actions/download-artifact@v4
        with:
          name: webrtc-server-package

      - name: Set Role ARN
        run: |
          if [[ "${{ needs.build.outputs.environment }}" == "develop" ]]; then
            echo "ROLE_ARN=${{ secrets.AWS_ROLE_TO_ASSUME_DEVELOP }}" >> $GITHUB_ENV
          elif [[ "${{ needs.build.outputs.environment }}" == "qa" ]]; then
            echo "ROLE_ARN=${{ secrets.AWS_ROLE_TO_ASSUME_QA }}" >> $GITHUB_ENV
          elif [[ "${{ needs.build.outputs.environment }}" == "staging" ]]; then
            echo "ROLE_ARN=${{ secrets.AWS_ROLE_TO_ASSUME_STAGING }}" >> $GITHUB_ENV
          # NOTE: main environment is NOT USED for this project (only main2)
          # elif [[ "${{ needs.build.outputs.environment }}" == "main" ]]; then
          #   echo "ROLE_ARN=${{ secrets.AWS_ROLE_TO_ASSUME_MAIN }}" >> $GITHUB_ENV
          elif [[ "${{ needs.build.outputs.environment }}" == "main2" ]]; then
            echo "ROLE_ARN=${{ secrets.AWS_ROLE_TO_ASSUME_MAIN2 }}" >> $GITHUB_ENV
          fi

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: GitHubActions-WebRTC-Deploy-${{ needs.build.outputs.environment }}

      - name: Upload package to S3
        run: |
          echo "ðŸ“¤ Uploading ${{ needs.build.outputs.zip_filename }} to s3://${{ env.S3_BUCKET }}/"

          aws s3 cp \
            "${{ needs.build.outputs.zip_filename }}" \
            "s3://${{ env.S3_BUCKET }}/${{ needs.build.outputs.zip_filename }}" \
            --metadata "version=${{ needs.build.outputs.version }},git-sha=${GITHUB_SHA},deployed-by=${GITHUB_ACTOR},environment=${{ needs.build.outputs.environment }}" \
            --no-progress

          echo "âœ… Upload complete"

          # Verify upload
          aws s3 ls "s3://${{ env.S3_BUCKET }}/${{ needs.build.outputs.zip_filename }}"

      - name: Get EC2 instance ID from infrastructure outputs
        id: get-instance
        run: |
          ENVIRONMENT="${{ needs.build.outputs.environment }}"
          echo "ðŸ” Looking for WebRTC server instance in environment: ${ENVIRONMENT}"

          # Method 1: Query EC2 instances by tags
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters \
              "Name=tag:Name,Values=lgmk-flutter-webrtc-server-${ENVIRONMENT}" \
              "Name=instance-state-name,Values=running" \
            --query 'Reservations[0].Instances[0].InstanceId' \
            --output text 2>/dev/null || echo "None")

          if [[ "${INSTANCE_ID}" == "None" || -z "${INSTANCE_ID}" ]]; then
            echo "âš ï¸ Instance not found with exact tag match, trying wildcard search..."

            INSTANCE_ID=$(aws ec2 describe-instances \
              --filters \
                "Name=tag:Name,Values=*webrtc*${ENVIRONMENT}*" \
                "Name=instance-state-name,Values=running" \
              --query 'Reservations[0].Instances[0].InstanceId' \
              --output text 2>/dev/null || echo "None")
          fi

          if [[ "${INSTANCE_ID}" == "None" || -z "${INSTANCE_ID}" ]]; then
            echo "âš ï¸ Instance not found. This might be expected if WebRTC server is not enabled for ${ENVIRONMENT}."
            echo "ðŸ’¡ Check terraform/environments/${ENVIRONMENT}.tfvars in lgmk-pers-base-infra project."
            echo "ðŸ’¡ Variable 'enable_webrtc_server' must be set to 'true'."

            # List available instances for debugging
            echo ""
            echo "ðŸ“‹ Available WebRTC instances:"
            aws ec2 describe-instances \
              --filters \
                "Name=tag:Name,Values=*webrtc*" \
                "Name=instance-state-name,Values=running" \
              --query 'Reservations[].Instances[].[InstanceId,Tags[?Key==`Name`].Value|[0],Tags[?Key==`Environment`].Value|[0],State.Name]' \
              --output table || true

            exit 1
          fi

          echo "instance_id=${INSTANCE_ID}" >> $GITHUB_OUTPUT
          echo "âœ… Found instance: ${INSTANCE_ID}"

          # Get instance details
          aws ec2 describe-instances \
            --instance-ids "${INSTANCE_ID}" \
            --query 'Reservations[0].Instances[0].[InstanceId,PublicIpAddress,PrivateIpAddress,State.Name]' \
            --output table

      - name: Verify instance has SSM agent
        run: |
          echo "ðŸ” Verifying SSM agent connectivity..."

          # Check if instance is managed by SSM
          SSM_STATUS=$(aws ssm describe-instance-information \
            --filters "Key=InstanceIds,Values=${{ steps.get-instance.outputs.instance_id }}" \
            --query 'InstanceInformationList[0].PingStatus' \
            --output text 2>/dev/null || echo "NotFound")

          if [[ "${SSM_STATUS}" != "Online" ]]; then
            echo "âŒ SSM agent is not online for instance ${{ steps.get-instance.outputs.instance_id }}"
            echo "ðŸ’¡ Ensure the EC2 instance has:"
            echo "   - SSM agent installed and running"
            echo "   - IAM role with AmazonSSMManagedInstanceCore policy"
            echo "   - Network connectivity to SSM endpoints"
            exit 1
          fi

          echo "âœ… SSM agent is online"

      - name: Execute deployment via SSM
        id: deploy
        run: |
          echo "ðŸš€ Deploying to EC2 instance: ${{ steps.get-instance.outputs.instance_id }}"
          echo "ðŸ“¦ Package: ${{ needs.build.outputs.zip_filename }}"
          echo "ðŸŽ¯ Environment: ${{ needs.build.outputs.environment }}"

          COMMAND_ID=$(aws ssm send-command \
            --instance-ids "${{ steps.get-instance.outputs.instance_id }}" \
            --document-name "AWS-RunShellScript" \
            --comment "Deploy WebRTC Server ${{ needs.build.outputs.version }} to ${{ needs.build.outputs.environment }}" \
            --parameters 'commands=[
              "set -eu",
              "echo \"==> WebRTC Server Deployment\"",
              "echo \"    Version: ${{ needs.build.outputs.version }}\"",
              "echo \"    Package: ${{ needs.build.outputs.zip_filename }}\"",
              "echo \"    Environment: ${{ needs.build.outputs.environment }}\"",
              "echo \"    Git SHA: ${{ github.sha }}\"",
              "echo \"\"",
              "cd /home/ubuntu",
              "if [ ! -f deploy-flutter-webrtc-server.sh ]; then echo \"âŒ ERROR: Deployment script not found at /home/ubuntu/deploy-flutter-webrtc-server.sh\"; exit 1; fi",
              "echo \"==> Executing deployment script...\"",
              "bash deploy-flutter-webrtc-server.sh -b ${{ env.S3_BUCKET }} -f ${{ needs.build.outputs.zip_filename }} -s ${{ env.SERVICE_NAME }}",
              "echo \"\"",
              "echo \"âœ… Deployment completed successfully\""
            ]' \
            --timeout-seconds 600 \
            --output text \
            --query 'Command.CommandId')

          echo "command_id=${COMMAND_ID}" >> $GITHUB_OUTPUT
          echo "ðŸ“‹ SSM Command ID: ${COMMAND_ID}"

          # Wait for command to complete
          echo "â³ Waiting for deployment to complete..."
          echo ""

          for i in {1..60}; do
            STATUS=$(aws ssm list-command-invocations \
              --command-id "${COMMAND_ID}" \
              --details \
              --query 'CommandInvocations[0].Status' \
              --output text)

            echo "  [$i/60] Status: ${STATUS}"

            if [[ "${STATUS}" == "Success" ]]; then
              echo ""
              echo "âœ… Deployment completed successfully"
              break
            elif [[ "${STATUS}" == "Failed" || "${STATUS}" == "Cancelled" || "${STATUS}" == "TimedOut" ]]; then
              echo ""
              echo "âŒ Deployment failed with status: ${STATUS}"

              # Get command output for debugging
              echo ""
              echo "ðŸ“ Command output:"
              aws ssm get-command-invocation \
                --command-id "${COMMAND_ID}" \
                --instance-id "${{ steps.get-instance.outputs.instance_id }}" \
                --query 'StandardOutputContent' \
                --output text

              echo ""
              echo "ðŸ“ Command errors:"
              aws ssm get-command-invocation \
                --command-id "${COMMAND_ID}" \
                --instance-id "${{ steps.get-instance.outputs.instance_id }}" \
                --query 'StandardErrorContent' \
                --output text

              exit 1
            fi

            sleep 10
          done

          if [[ "${STATUS}" != "Success" ]]; then
            echo ""
            echo "âŒ Deployment timed out after 10 minutes"
            exit 1
          fi

      - name: Get deployment logs
        if: always()
        run: |
          echo "ðŸ“ Fetching deployment logs..."
          echo ""

          aws ssm get-command-invocation \
            --command-id "${{ steps.deploy.outputs.command_id }}" \
            --instance-id "${{ steps.get-instance.outputs.instance_id }}" \
            --query 'StandardOutputContent' \
            --output text || echo "No output available"

      - name: Verify service health
        run: |
          echo "ðŸ” Verifying service health..."

          # Check service status via SSM
          HEALTH_CMD_ID=$(aws ssm send-command \
            --instance-ids "${{ steps.get-instance.outputs.instance_id }}" \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=[
              "echo \"==> Service Status\"",
              "sudo systemctl is-active ${{ env.SERVICE_NAME }} && echo \"âœ… Service is active\" || echo \"âŒ Service is NOT active\"",
              "echo \"\"",
              "echo \"==> Detailed Status\"",
              "sudo systemctl status ${{ env.SERVICE_NAME }} --no-pager -l"
            ]' \
            --timeout-seconds 60 \
            --query 'Command.CommandId' \
            --output text)

          # Wait for health check
          sleep 5

          echo ""
          echo "ðŸ“‹ Health check output:"
          aws ssm get-command-invocation \
            --command-id "${HEALTH_CMD_ID}" \
            --instance-id "${{ steps.get-instance.outputs.instance_id }}" \
            --query 'StandardOutputContent' \
            --output text

          echo ""
          echo "âœ… Health check complete"

      - name: Create deployment summary
        if: always()
        run: |
          cat >> $GITHUB_STEP_SUMMARY <<'EOF'
          ## ðŸš€ Deployment Summary

          **Version:** ${{ needs.build.outputs.version }}
          **Package:** ${{ needs.build.outputs.zip_filename }}
          **Environment:** ${{ needs.build.outputs.environment }}
          **Instance:** ${{ steps.get-instance.outputs.instance_id }}
          **Deployed by:** ${{ github.actor }}
          **Git SHA:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}

          ### ðŸ“¦ Deployment Details
          - **S3 Location:** `s3://${{ env.S3_BUCKET }}/${{ needs.build.outputs.zip_filename }}`
          - **Service:** `${{ env.SERVICE_NAME }}`
          - **SSM Command:** `${{ steps.deploy.outputs.command_id }}`
          - **AWS Region:** `${{ env.AWS_REGION }}`

          ### âœ… Status
          Deployment completed successfully! ðŸŽ‰

          ---

          ### ðŸ“‹ Post-Deployment Checklist
          - [ ] Verify service is running: `sudo systemctl status ${{ env.SERVICE_NAME }}`
          - [ ] Check logs: `sudo journalctl -u ${{ env.SERVICE_NAME }} -f`
          - [ ] Test WebSocket endpoint: `https://<instance-ip>:8086/`
          - [ ] Test TURN server connectivity
          EOF
